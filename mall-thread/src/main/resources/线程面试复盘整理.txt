
================================= 第一节：并发编程之JMM&volatile详解(上)=======================

CPU通过IO总线把内存(总存储器)上的指令加载到CPU Cache中(多级缓存)

三级缓存 处理速度  寄存器>L1>L2>L3

如果想把CPU计算出来的结果必须立马刷回主内存，需要怎么做？  发送一个#Lock信号 MESI(缓存一致性协议)

1：总线加锁
若存在多个CPU，其中一个CPU要从主内存加载一块数据，在加载数据之前，会对这个数据进行总线加锁，这样其他CPU就不能在读写这块数据。

2：缓存一致性协议(MESI)
MESI：代表了四种状态

M：修改
E：独享，互斥
S：共享
I：无效


总线嗅探机制(时刻监听)


E-S-【(锁住缓存行)-M(往总线上发消息)】----其他CPU经过嗅探机制监听到消息，将数据变为I
同步之后又变成E

CPU缓存中最小存储单元(缓存行)


什么原因会导致缓存行失效？
1：数据的存储长度大于一个缓存行，加总线锁。
2：CPU本身并不支持缓存一致性协议


2>什么是线程？
进程是系统分配资源的基本单位，线程是调度CPU的基本单位，一个进程中至少包含一个执行线程，线程寄生在进程当中。

线程分为两类：
用户级线程(ULT)
内核级线程(KLT)



=================================第二节：并发编程之JMM&volatile详解（中）========================

1：Java线程生命状态

2：为什么要用到并发

1、充分利用多核CPU的计算能力    2、方便进行业务拆分，提升应用性能

并发产生的问题：

高并发场景下，导致频繁的上下文切换
临界区线程安全问题，容易出现死锁的，产生死锁就会造成系统功能不可用


3：JMM模型，是一种规范，屏蔽不同操作系统底层的差异，JMM模型围绕原子性，有序性，可见行展开


Java内存模型内存交互操作：

lock(锁定)：作用于主内存的变量，把一个变量标记为一条线程独占状态
unlock(解锁)：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定
read(读取)：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用
load(载入)：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中
use(使用)：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎
assign(赋值)：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量
store(存储)：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作
write(写入)：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中

加入内存屏障标示后，指令就不会被重排序了



==================================第三节：并发编程之JMM&volatile详解（下）==================================

volatile：有序性，禁止指令重排序(基于内存屏障)
volatile：轻量级的同步锁
内存屏障分为四种
store&store
store&load
load&load
load&store


指令重排发生在哪个阶段？
1：执行器编译阶段(字节码翻译成机器码)
2：CPU运行时
发生指令重排时，要保证在单线程下运行结果保持不变



大量使用CAS(自旋)和Volatile关键字会产生什么问题？


有没有遇见过总线风暴？在什么情况下会导致总线风暴？

工作内存跟我们的主内存会产生大量的交互，大量的交互需要总线来进行交互
当在高并发场景下，会产生大量的无效的工作内存变量。

解决方案是：可以采用加锁方式


private volatile  static  Person person;
单例中双重检查锁：

public static Person getInstance(){
      if(person ==null){
         synchronized(Person.class){
            if(person ==null){
              person = new Person();
            }
         }
      }
   return person;
}


#申请内存空间
#实例化对象
#填充数据(赋值)





==============================第四节:并发编程之synchronized&Lock&AQS详解=========================

synchronized：并发访问保证串行化，没有抢到锁的线程会放到一个名叫WaitSet的集合内。


加锁目的：序列化访问临界资源(共享资源)，即同一时刻只能有一个线程访问临界资源。


ReentrantLock，实现了JUC里的Lock接口，基于AQS实现，需要手动加锁和解锁(lock(),unlock())

每一个对象Object被创建之后，都会在JVM内部维护一个与之对应的Monitor对象(监视器锁)

认识对象的内存结构：
对象头：比如 hash码，对象所属的年代，对象锁，锁状态标志，偏向锁（线程）ID，偏向时间，数组长度（数组对象）等

对象实际数据：即创建对象时，对象中成员变量，方法等
对齐填充：对象的大小必须是8字节的整数倍

逃逸分析：Jit编译是会对代码进行逃逸分析优化

如果一个方法中，产生的对像不会被其他线程引用，可能不会逃逸行为，对象实例直接在栈内存分配

开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0
JDK1.6之后默认是开启偏向锁的，开启偏向锁性能会提高10%


========================第五节：并发编程之synchronized&Lock&AQS详解（下）==================================
偏向锁：不会自动释放
轻量级锁：线程竞争不激烈，交替执行，-没有抢到锁的线程不会被阻塞，而是在自旋(不会丢弃CPU执行权)去等待获取锁

ReentrantLock    CLH队列(同步队列)

如果Node在条件队列当中，Node必须是独占模式(不能是共享)



=============================第七节：并发编程之Atomic&Unsafe魔法类详解=======================================


=============================第八节：并发编程之Collections&Queue体系分析====================================
BlockingQueue队列  内部主要实现使用
ReentrantLock &Condition

条件队列(condition)只能在独占模式下使用

put操作：
1，先要获取独占锁
2，判断当前对列是否已经满了

条件队列中的线程是不会被唤醒去竞争锁资源的


Java1.7中HashMap死锁的问题？  数组+链表

Java1.8中HashMap中不会死锁

死锁的原因，HashMap在多线程场景下，扩容期间存在节点位置互换指针引用的问题，有可能会导致死锁


什么时候需要用到线程池？
单个任务处理时间比较短
需要处理的任务数量很大


计算(CPU)密集型
I/O密集型

逃逸分析发生在我们即时编译期


jmap --heap



















































